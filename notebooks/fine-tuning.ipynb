{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# **Fine-Tuning GPT-4o mini on Custom Dataset**\n",
        "\n",
        "**The fine-tuned model is designed to assist real estate agents in efficiently searching for property information, providing concise and relevant responses to their queries.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 1: Install all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\akaruparti\\anaconda\\lib\\site-packages (1.12.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
            "ERROR: No matching distribution found for json\n"
          ]
        }
      ],
      "source": [
        "!pip install openai json requests os time tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1709154395410
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 2: Please set up environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1709238560906
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "load_dotenv(\"azure.env\")\n",
        "\n",
        "\n",
        "openai.api_type: str = \"azure\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
        "openai.api_version = \"2024-07-18\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: c:\\Users\\akaruparti\\Documents\\gpt-4o-mini-FT\\GPT4o-mini-fine-tuning\\notebooks\n",
            "New working directory: c:\\Users\\akaruparti\\Documents\\gpt-4o-mini-FT\\GPT4o-mini-fine-tuning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(f\"Current working directory: {current_directory}\")\n",
        "\n",
        "# Set the current working directory to the desired path\n",
        "desired_directory = \"c:\\\\Users\\\\akaruparti\\\\Documents\\\\gpt-4o-mini-FT\\\\GPT4o-mini-fine-tuning\\\\\" # Replace this with the actual path if different\n",
        "os.chdir(desired_directory)\n",
        "print(f\"New working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 3: Load the training data, validation data and testing data provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1709154396091
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of examples in training set: 10\n",
            "First example in training set:\n",
            "{'role': 'system', 'content': 'You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.'}\n",
            "{'role': 'user', 'content': 'What is the price of the property at 123 Main Street?'}\n",
            "{'role': 'assistant', 'content': 'The property at 123 Main Street is listed at $450,000. Would you like more details or schedule a viewing?'}\n",
            "Number of examples in training set: 10\n",
            "First example in training set:\n",
            "{'role': 'system', 'content': 'You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.'}\n",
            "{'role': 'user', 'content': 'What is the price of the property at 123 Main Street?'}\n",
            "{'role': 'assistant', 'content': 'The property at 123 Main Street is listed at $450,000. Would you like more details or schedule a viewing?'}\n",
            "\n",
            "Number of examples in validation set: 11\n",
            "First example in validation set:\n",
            "{'role': 'system', 'content': 'You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.'}\n",
            "{'role': 'user', 'content': 'Is the property at 321 Maple Road close to schools?'}\n",
            "{'role': 'assistant', 'content': 'Yes, the property at 321 Maple Road is within 2 miles of several schools. Would you like details on specific schools or the overall neighborhood?'}\n"
          ]
        }
      ],
      "source": [
        "# Load the training set\n",
        "with open('data/training_data.jsonl', 'r', encoding='utf-8-sig') as f:\n",
        "    training_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Training dataset stats\n",
        "print(\"Number of examples in training set:\", len(training_dataset))\n",
        "print(\"First example in training set:\")\n",
        "for message in training_dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Load the validation set\n",
        "with open('data/validation_data.jsonl', 'r', encoding='utf-8-sig') as f:\n",
        "    validation_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "\n",
        "# Training dataset stats\n",
        "print(\"Number of examples in training set:\", len(training_dataset))\n",
        "print(\"First example in training set:\")\n",
        "for message in training_dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "\n",
        "# Validation dataset stats\n",
        "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
        "print(\"First example in validation set:\")\n",
        "for message in validation_dataset[0][\"messages\"]:\n",
        "    print(message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 4: Token Count Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1709154399062
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file: data/training_data.jsonl\n",
            "\n",
            "#### Distribution of total tokens:\n",
            "min / max: 81, 104\n",
            "mean / median: 92.4, 93.0\n",
            "p5 / p95: 85.5, 98.6\n",
            "\n",
            "#### Distribution of assistant tokens:\n",
            "min / max: 23, 33\n",
            "mean / median: 27.6, 26.5\n",
            "p5 / p95: 23.9, 32.1\n",
            "**************************************************\n",
            "Processing file: data/validation_data.jsonl\n",
            "\n",
            "#### Distribution of total tokens:\n",
            "min / max: 82, 100\n",
            "mean / median: 93.18181818181819, 95.0\n",
            "p5 / p95: 83.0, 99.0\n",
            "\n",
            "#### Distribution of assistant tokens:\n",
            "min / max: 25, 37\n",
            "mean / median: 29.636363636363637, 30.0\n",
            "p5 / p95: 26.0, 36.0\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
        "\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "files = ['data/training_data.jsonl', 'data/validation_data.jsonl']\n",
        "\n",
        "for file in files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "    with open(file, 'r', encoding='utf-8-sig') as f:\n",
        "        dataset = [json.loads(line) for line in f]\n",
        "\n",
        "    total_tokens = []\n",
        "    assistant_tokens = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        messages = ex.get(\"messages\", {})\n",
        "        total_tokens.append(num_tokens_from_messages(messages))\n",
        "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
        "    \n",
        "    print_distribution(total_tokens, \"total tokens\")\n",
        "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
        "    print('*' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 5: Upload training files to Azure Open AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1709233800632
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure API Base: https://aoaiswedencentral0312.openai.azure.com/\n",
            "Azure API Key: dbe46fb62095427b82e7fd020712f684\n",
            "Training file ID: file-6d2cc21ba5ca4484b72e285aa45ef584\n",
            "Validation file ID: file-09e046e935914ec19d7e227c361f9445\n"
          ]
        }
      ],
      "source": [
        "# Initialize AzureOpenAI client\n",
        "\n",
        "load_dotenv(\"azure.env\")\n",
        "\n",
        "print(\"Azure API Base:\", os.getenv(\"OPENAI_API_BASE\"))\n",
        "print(\"Azure API Key:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint=os.getenv(\"OPENAI_API_BASE\"), \n",
        "  api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
        "  api_version=\"2024-05-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
        ")\n",
        "\n",
        "training_file_name = 'data/training_data.jsonl'\n",
        "validation_file_name = 'data/validation_data.jsonl'\n",
        "\n",
        "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response.id\n",
        "\n",
        "validation_response = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file_id = validation_response.id\n",
        "\n",
        "print(\"Training file ID:\", training_file_id)\n",
        "print(\"Validation file ID:\", validation_file_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 6: Submit your fine-tuning job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1709233805984
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job ID: ftjob-7153a4e1c0fd4ab3af8a3b8fec7fe2c5\n",
            "Status: pending\n",
            "{\n",
            "  \"id\": \"ftjob-7153a4e1c0fd4ab3af8a3b8fec7fe2c5\",\n",
            "  \"created_at\": 1724090046,\n",
            "  \"error\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"finished_at\": null,\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": -1,\n",
            "    \"batch_size\": -1,\n",
            "    \"learning_rate_multiplier\": 1\n",
            "  },\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"organization_id\": null,\n",
            "  \"result_files\": null,\n",
            "  \"status\": \"pending\",\n",
            "  \"trained_tokens\": null,\n",
            "  \"training_file\": \"file-6d2cc21ba5ca4484b72e285aa45ef584\",\n",
            "  \"validation_file\": \"file-09e046e935914ec19d7e227c361f9445\",\n",
            "  \"seed\": 1105642612\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    model=\"gpt-4o-mini\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
        "\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "# You can use the job ID to monitor the status of the fine-tuning job.\n",
        "# The fine-tuning job will take some time to start and complete.\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)\n",
        "print(response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 7: Track Training Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1709237242576
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"ftjob-7153a4e1c0fd4ab3af8a3b8fec7fe2c5\",\n",
            "  \"created_at\": 1724090046,\n",
            "  \"error\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"finished_at\": null,\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": -1,\n",
            "    \"batch_size\": -1,\n",
            "    \"learning_rate_multiplier\": 1\n",
            "  },\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"organization_id\": null,\n",
            "  \"result_files\": null,\n",
            "  \"status\": \"pending\",\n",
            "  \"trained_tokens\": null,\n",
            "  \"training_file\": \"file-6d2cc21ba5ca4484b72e285aa45ef584\",\n",
            "  \"validation_file\": \"file-09e046e935914ec19d7e227c361f9445\",\n",
            "  \"seed\": 1105642612\n",
            "}\n",
            "Elapsed time: 17 minutes 17 seconds\n",
            "Status: pending\n"
          ]
        }
      ],
      "source": [
        "# Track training status\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Get the status of our fine-tuning job.\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "status = response.status\n",
        "\n",
        "# If the job isn't done yet, poll it every 10 seconds.\n",
        "while status not in [\"succeeded\", \"failed\"]:\n",
        "    time.sleep(10)\n",
        "    \n",
        "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    print(response.model_dump_json(indent=2))\n",
        "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
        "    status = response.status\n",
        "    print(f'Status: {status}')\n",
        "    clear_output(wait=True)\n",
        "\n",
        "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
        "\n",
        "# List all fine-tuning jobs for this resource.\n",
        "print('Checking other fine-tune jobs for this resource.')\n",
        "response = client.fine_tuning.jobs.list()\n",
        "print(f'Found {len(response.data)} fine-tune jobs.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 8: Retrieve Fine Tuned Model Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1709238394955
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"ftjob-1478253d632e49b5a4b9d7ba4878c093\",\n",
            "  \"created_at\": 1709233806,\n",
            "  \"error\": null,\n",
            "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093\",\n",
            "  \"finished_at\": 1709237242,\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": -1,\n",
            "    \"batch_size\": -1,\n",
            "    \"learning_rate_multiplier\": 1\n",
            "  },\n",
            "  \"model\": \"gpt-35-turbo-0613\",\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"organization_id\": null,\n",
            "  \"result_files\": [\n",
            "    \"file-8b260538c8874385a100fed1c0df0e61\"\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"trained_tokens\": -13313,\n",
            "  \"training_file\": \"file-1c4a7c22278a49428e8dbedee4b77818\",\n",
            "  \"validation_file\": \"file-c794fc59686f49a6a4b0a7fa5f198c7f\",\n",
            "  \"updated_at\": 1709237242\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "print(response.model_dump_json(indent=2))\n",
        "fine_tuned_model = response.fine_tuned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 9 : Deploy a fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1709238886001
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new deployment...\n",
            "<Response [201]>\n",
            "Created\n",
            "{'id': '/subscriptions/559395b4-36ba-437a-a7c1-224ff54723e0/resourceGroups/AOAI-Shared/providers/Microsoft.CognitiveServices/accounts/AOAI-SwedenCentral-4All/deployments/gpt-35-turbo', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-35-turbo', 'sku': {'name': 'standard', 'capacity': 1}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093', 'version': '3'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'currentCapacity': 1, 'capabilities': {'chatCompletion': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 10, 'count': 1}, {'key': 'token', 'renewalPeriod': 60, 'count': 1000}]}, 'systemData': {'createdBy': 'anurag.sirish@gmail.com', 'createdByType': 'User', 'createdAt': '2024-02-29T20:34:38.2610458Z', 'lastModifiedBy': 'anurag.sirish@gmail.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2024-02-29T20:34:38.2610458Z'}, 'etag': '\"9c967f0f-80a3-4884-8d0d-9b4b1f7fb6ea\"'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "token= os.getenv(\"TEMP_AUTH_TOKEN\") \n",
        "subscription = \"559395b4-36ba-437a-a7c1-224ff54723e0\"  \n",
        "resource_group = \"AOAI-Shared\"\n",
        "resource_name = \"AOAI-SwedenCentral-4All\"\n",
        "model_deployment_name =\"gpt-35-turbo\"\n",
        "\n",
        "deploy_params = {'api-version': \"2023-10-01-preview\"} \n",
        "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
        "\n",
        "deploy_data = {\n",
        "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
        "    \"properties\": {\n",
        "        \"model\": {\n",
        "            \"format\": \"OpenAI\",\n",
        "            \"name\": \"gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
        "            \"version\": \"3\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "deploy_data = json.dumps(deploy_data)\n",
        "\n",
        "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
        "\n",
        "print('Creating a new deployment...')\n",
        "\n",
        "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
        "\n",
        "print(r)\n",
        "print(r.reason)\n",
        "print(r.json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Sample Testing 1\n",
        "\n",
        "### Classifies a complex question as 'Legal' accurately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1709239840519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Legal\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
        "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "  api_version=\"2023-10-01-preview\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a classification model. Classify questions into different domains.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Is a verbal agreement enforceable when no written documentation exists, and under what circumstances might it be recognized?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Sample Testing 2\n",
        "\n",
        "### Classifies a complex question as 'HR' accurately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1709240017285
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HR\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a classification model. Classify questions into different domains.\"},\n",
        "        {\"role\": \"user\", \"content\": \"In a situation where an individual reports feeling targeted due to a characteristic protected by federal standards and experiences conduct contributing to an unwelcoming work atmosphere, what steps should be taken to initiate a thorough internal review to ensure adherence to relevant statutes, while also protecting the privacy and rights of everyone involved, and what actions are necessary to maintain team cohesion and efficiency throughout this period?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Challenge: Now use the test dataset questions provided and evaluate the model for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
