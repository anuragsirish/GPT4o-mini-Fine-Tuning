{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# **Fine-Tuning GPT-4o mini on Custom Dataset**\n",
        "\n",
        "**The fine-tuned model is designed to assist real estate agents in efficiently searching for property information, providing concise and relevant responses to their queries.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 1: Install all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\akaruparti\\anaconda\\lib\\site-packages (1.12.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
            "ERROR: No matching distribution found for json\n"
          ]
        }
      ],
      "source": [
        "!pip install openai json requests os time tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1709154395410
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 2: Please set up environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1709238560906
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "load_dotenv(\"azure.env\")\n",
        "\n",
        "\n",
        "openai.api_type: str = \"azure\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
        "openai.api_version = \"2024-07-18\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: c:\\Users\\akaruparti\\Documents\\gpt-4o-mini-FT\\GPT4o-mini-fine-tuning\n",
            "New working directory: c:\\Users\\akaruparti\\Documents\\gpt-4o-mini-FT\\GPT4o-mini-fine-tuning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(f\"Current working directory: {current_directory}\")\n",
        "\n",
        "# Set the current working directory to the desired path\n",
        "desired_directory = \"c:\\\\Users\\\\akaruparti\\\\Documents\\\\gpt-4o-mini-FT\\\\GPT4o-mini-fine-tuning\\\\\" # Replace this with the actual path if different\n",
        "os.chdir(desired_directory)\n",
        "print(f\"New working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 3: Load the training data, validation data and testing data provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1709154396091
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of examples in training set: 10\n",
            "First example in training set:\n",
            "{'role': 'system', 'content': 'You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.'}\n",
            "{'role': 'user', 'content': 'What is the price of the property at 123 Main Street?'}\n",
            "{'role': 'assistant', 'content': 'The property at 123 Main Street is listed at $450,000. Would you like more details or schedule a viewing?'}\n",
            "Number of examples in training set: 10\n",
            "First example in training set:\n",
            "{'role': 'system', 'content': 'You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.'}\n",
            "{'role': 'user', 'content': 'What is the price of the property at 123 Main Street?'}\n",
            "{'role': 'assistant', 'content': 'The property at 123 Main Street is listed at $450,000. Would you like more details or schedule a viewing?'}\n",
            "\n",
            "Number of examples in validation set: 11\n",
            "First example in validation set:\n",
            "{'role': 'system', 'content': 'You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.'}\n",
            "{'role': 'user', 'content': 'Is the property at 321 Maple Road close to schools?'}\n",
            "{'role': 'assistant', 'content': 'Yes, the property at 321 Maple Road is within 2 miles of several schools. Would you like details on specific schools or the overall neighborhood?'}\n"
          ]
        }
      ],
      "source": [
        "# Load the training set\n",
        "with open('data/training_data.jsonl', 'r', encoding='utf-8-sig') as f:\n",
        "    training_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Training dataset stats\n",
        "print(\"Number of examples in training set:\", len(training_dataset))\n",
        "print(\"First example in training set:\")\n",
        "for message in training_dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Load the validation set\n",
        "with open('data/validation_data.jsonl', 'r', encoding='utf-8-sig') as f:\n",
        "    validation_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "\n",
        "# Training dataset stats\n",
        "print(\"Number of examples in training set:\", len(training_dataset))\n",
        "print(\"First example in training set:\")\n",
        "for message in training_dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "\n",
        "# Validation dataset stats\n",
        "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
        "print(\"First example in validation set:\")\n",
        "for message in validation_dataset[0][\"messages\"]:\n",
        "    print(message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 4: Token Count Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1709154399062
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file: data/training_data.jsonl\n",
            "\n",
            "#### Distribution of total tokens:\n",
            "min / max: 81, 104\n",
            "mean / median: 92.4, 93.0\n",
            "p5 / p95: 85.5, 98.6\n",
            "\n",
            "#### Distribution of assistant tokens:\n",
            "min / max: 23, 33\n",
            "mean / median: 27.6, 26.5\n",
            "p5 / p95: 23.9, 32.1\n",
            "**************************************************\n",
            "Processing file: data/validation_data.jsonl\n",
            "\n",
            "#### Distribution of total tokens:\n",
            "min / max: 82, 100\n",
            "mean / median: 93.18181818181819, 95.0\n",
            "p5 / p95: 83.0, 99.0\n",
            "\n",
            "#### Distribution of assistant tokens:\n",
            "min / max: 25, 37\n",
            "mean / median: 29.636363636363637, 30.0\n",
            "p5 / p95: 26.0, 36.0\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
        "\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "files = ['data/training_data.jsonl', 'data/validation_data.jsonl']\n",
        "\n",
        "for file in files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "    with open(file, 'r', encoding='utf-8-sig') as f:\n",
        "        dataset = [json.loads(line) for line in f]\n",
        "\n",
        "    total_tokens = []\n",
        "    assistant_tokens = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        messages = ex.get(\"messages\", {})\n",
        "        total_tokens.append(num_tokens_from_messages(messages))\n",
        "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
        "    \n",
        "    print_distribution(total_tokens, \"total tokens\")\n",
        "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
        "    print('*' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 5: Upload training files to Azure Open AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1709233800632
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure API Base: https://aoaiswedencentral0312.openai.azure.com/\n",
            "Azure API Key: dbe46fb62095427b82e7fd020712f684\n",
            "Training file ID: file-eb6a9476d11247c88838a18e607bcd19\n",
            "Validation file ID: file-0e0b5ccd2a474af3966073f449a44778\n"
          ]
        }
      ],
      "source": [
        "# Initialize AzureOpenAI client\n",
        "\n",
        "load_dotenv(\"azure.env\")\n",
        "\n",
        "print(\"Azure API Base:\", os.getenv(\"OPENAI_API_BASE\"))\n",
        "print(\"Azure API Key:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint=os.getenv(\"OPENAI_API_BASE\"), \n",
        "  api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
        "  api_version=\"2024-05-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
        ")\n",
        "\n",
        "training_file_name = 'data/training_data.jsonl'\n",
        "validation_file_name = 'data/validation_data.jsonl'\n",
        "\n",
        "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response.id\n",
        "\n",
        "validation_response = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file_id = validation_response.id\n",
        "\n",
        "print(\"Training file ID:\", training_file_id)\n",
        "print(\"Validation file ID:\", validation_file_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 6: Submit your fine-tuning job\n",
        "### Take close to 45 minutes to fine-tune the model with a dataset consisting of 10 samples and 91000 tokens\n",
        "\n",
        "![alt text](image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1709233805984
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job ID: ftjob-ba7c72eaeda14eda87a76271b6a80e24\n",
            "Status: pending\n",
            "{\n",
            "  \"id\": \"ftjob-ba7c72eaeda14eda87a76271b6a80e24\",\n",
            "  \"created_at\": 1724251727,\n",
            "  \"error\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"finished_at\": null,\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": -1,\n",
            "    \"batch_size\": -1,\n",
            "    \"learning_rate_multiplier\": 1\n",
            "  },\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"organization_id\": null,\n",
            "  \"result_files\": null,\n",
            "  \"status\": \"pending\",\n",
            "  \"trained_tokens\": null,\n",
            "  \"training_file\": \"file-eb6a9476d11247c88838a18e607bcd19\",\n",
            "  \"validation_file\": \"file-0e0b5ccd2a474af3966073f449a44778\",\n",
            "  \"seed\": 1388987542\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    model=\"gpt-4o-mini\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
        "\n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "# You can use the job ID to monitor the status of the fine-tuning job.\n",
        "# The fine-tuning job will take some time to start and complete.\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)\n",
        "print(response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 7: Track Training Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1709237242576
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning job ftjob-ba7c72eaeda14eda87a76271b6a80e24 finished with status: succeeded\n",
            "Checking other fine-tune jobs for this resource.\n",
            "Found 3 fine-tune jobs.\n"
          ]
        }
      ],
      "source": [
        "# Track training status\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Get the status of our fine-tuning job.\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "status = response.status\n",
        "\n",
        "# If the job isn't done yet, poll it every 10 seconds.\n",
        "while status not in [\"succeeded\", \"failed\"]:\n",
        "    time.sleep(10)\n",
        "    \n",
        "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    print(response.model_dump_json(indent=2))\n",
        "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
        "    status = response.status\n",
        "    print(f'Status: {status}')\n",
        "    clear_output(wait=True)\n",
        "\n",
        "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
        "\n",
        "# List all fine-tuning jobs for this resource.\n",
        "print('Checking other fine-tune jobs for this resource.')\n",
        "response = client.fine_tuning.jobs.list()\n",
        "print(f'Found {len(response.data)} fine-tune jobs.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 8: Retrieve Fine Tuned Model Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1709238394955
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"ftjob-ba7c72eaeda14eda87a76271b6a80e24\",\n",
            "  \"created_at\": 1724251727,\n",
            "  \"error\": null,\n",
            "  \"fine_tuned_model\": \"gpt-4o-mini-2024-07-18.ft-ba7c72eaeda14eda87a76271b6a80e24\",\n",
            "  \"finished_at\": 1724254215,\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 10,\n",
            "    \"batch_size\": 1,\n",
            "    \"learning_rate_multiplier\": 1\n",
            "  },\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"organization_id\": null,\n",
            "  \"result_files\": [\n",
            "    \"file-34f0666467f24d10b4854f94735d4e89\"\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"trained_tokens\": 9240,\n",
            "  \"training_file\": \"file-eb6a9476d11247c88838a18e607bcd19\",\n",
            "  \"validation_file\": \"file-0e0b5ccd2a474af3966073f449a44778\",\n",
            "  \"seed\": 1388987542\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "print(response.model_dump_json(indent=2))\n",
        "fine_tuned_model = response.fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuned model ID: gpt-4o-mini-2024-07-18.ft-ba7c72eaeda14eda87a76271b6a80e24\n"
          ]
        }
      ],
      "source": [
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "\n",
        "if fine_tuned_model_id is None:\n",
        "    raise RuntimeError(\n",
        "        \"Fine-tuned model ID not found. Your job has likely not been completed yet.\"\n",
        "    )\n",
        "\n",
        "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 9 : Deploy the fine tuned model on Azure AI Studio. This can be done programmatically too. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Sample Testing 1\n",
        "\n",
        "### Now ask the fine-tuned models if there is any park near a particular property. It will respond to the information based on the language used in the trained data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "gather": {
          "logged": 1709239840519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, there is a large park within walking distance of the property on 110 Grove Street. Would you like more information about the amenities in the area?\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint=os.getenv(\"OPENAI_API_BASE\"), \n",
        "  api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
        "  api_version=\"2024-05-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini-2024-07-18-ft-ba7c72eaeda14eda87a76271b6a80e24\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a real estate customer support agent whose primary goal is to help users find and inquire about properties. You are friendly and concise. You only provide factual answers to queries and assist users in finding property information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Are there any nearby parks to the property on 110 Grove Street?\"},\n",
        "      \n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
