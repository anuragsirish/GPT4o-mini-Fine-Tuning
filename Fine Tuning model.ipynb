{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad5da8",
   "metadata": {},
   "source": [
    "# Fine tuning with Azure Open AI\n",
    "\n",
    "Documentation:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=command-line\n",
    "\n",
    "Information:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#fine-tuning-models-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10cc8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc40c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2023-09-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f3601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74027e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 23-Oct-2023 07:49:58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e58d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.28.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Open AI version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf48b6f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33df17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-35-turbo-16k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dde4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'> {\n",
      "  \"id\": \"chatcmpl-8CjzGbUtqE5LO9iWYTSkHI1LajZNB\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698047402,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Hello! How can I assist you today?\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"completion_tokens\": 9,\n",
      "    \"total_tokens\": 17\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "    max_tokens=100,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "print(\"Response:\\n\\n\", type(response), response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed1b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer type:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer type:\\n\\n\", type(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529206eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      " {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Hello! How can I assist you today?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\\n\\n\", response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a72f4",
   "metadata": {},
   "source": [
    "## Training and validation Jsonl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b591eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"training_set.jsonl\"\n",
    "validation_file_name = \"validation_set.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c86d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 2.7K Oct 17 15:35 training_set.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls $training_file_name -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0241b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the largest planet?\"}, {\"role\": \"assistant\", \"content\": \"It's called Jupiter, you may have heard of it...or not.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who painted the Mona Lisa?\"}, {\"role\": \"assistant\", \"content\": \"Oh, some obscure artist named Leonardo da Vinci. Not that he is famous or anything.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the boiling point of water?\"}, {\"role\": \"assistant\", \"content\": \"Exciting fact of the day: it's 100 degrees Celsius. Life-changing, isn't it?\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'The Odyssey'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some poet named Homer. Nothing special, really.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the largest mammal?\"}, {\"role\": \"assistant\", \"content\": \"Blue Whale. Quite a big fish isn't it? Oh wait, it's not a fish!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the highest mountain peak?\"}, {\"role\": \"assistant\", \"content\": \"Everest. Brace yourself, it's not a walk in the park.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who invented the telephone?\"}, {\"role\": \"assistant\", \"content\": \"A guy named Alexander Graham Bell. Bet you didn't guess that one!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the distance from Earth to the Sun?\"}, {\"role\": \"assistant\", \"content\": \"About 93 million miles. Just a quick drive, really.\"}]}\n"
     ]
    }
   ],
   "source": [
    "with open(training_file_name, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a23cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 2.6K Oct 17 15:35 validation_set.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls $validation_file_name -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7a5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the deepest part of the ocean?\"}, {\"role\": \"assistant\", \"content\": \"Mariana Trench, makes your swimming pool seem a bit shallow, doesn't it?\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who composed the 'Moonlight Sonata'?\"}, {\"role\": \"assistant\", \"content\": \"Just a little-known guy named Beethoven. No big deal.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What are the colors of the rainbow?\"}, {\"role\": \"assistant\", \"content\": \"ROYGBIV. Red, orange, yellow, green, blue, indigo, violet. Not that we learned this in preschool or anything!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the smallest planet?\"}, {\"role\": \"assistant\", \"content\": \"Meet Mercury, the runt of the solar system family.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Pride and Prejudice'?\"}, {\"role\": \"assistant\", \"content\": \"Do the words Jane Austen ring a bell? No? Well, she wrote it.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the largest desert?\"}, {\"role\": \"assistant\", \"content\": \"Antarctica. Surprise, surprise! Deserts aren't just full of sand, you know.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the longest river?\"}, {\"role\": \"assistant\", \"content\": \"The Nile River. It's not like it's famous or anything.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of Germany?\"}, {\"role\": \"assistant\", \"content\": \"Berlin. Shocking news, right?\"}]}\n"
     ]
    }
   ],
   "source": [
    "with open(validation_file_name, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67068a0c",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "071947eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
      "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the training set\n",
    "with open(training_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99485c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
      "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "with open(validation_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f10bd",
   "metadata": {},
   "source": [
    "## Tokens information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43160bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "990f2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    \"\"\"\n",
    "    Number of tokens from messages\n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "\n",
    "    num_tokens += 3\n",
    "\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c881646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac8dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution(values, name):\n",
    "    \"\"\"\n",
    "    Stats\n",
    "    \"\"\"\n",
    "    print(f\"Distribution of {name}:\")\n",
    "    print(f\"   min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"   mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"   p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97bcbc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing file: training_set.jsonl\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Distribution of total tokens:\n",
      "   min / max: 47, 62\n",
      "   mean / median: 52.1, 50.5\n",
      "   p5 / p95: 47.9, 57.5\n",
      "\n",
      "Distribution of assistant tokens:\n",
      "   min / max: 13, 30\n",
      "   mean / median: 17.6, 15.5\n",
      "   p5 / p95: 13.0, 21.9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing file: validation_set.jsonl\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Distribution of total tokens:\n",
      "   min / max: 43, 65\n",
      "   mean / median: 51.4, 49.0\n",
      "   p5 / p95: 45.7, 56.9\n",
      "\n",
      "Distribution of assistant tokens:\n",
      "   min / max: 8, 29\n",
      "   mean / median: 15.9, 13.5\n",
      "   p5 / p95: 11.6, 20.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = [training_file_name, validation_file_name]\n",
    "\n",
    "for file in files:\n",
    "    print()\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Processing file: {file}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bf2f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([48, 49, 56, 49, 65, 46, 56, 54, 48, 43],\n",
       " [13, 13, 19, 13, 29, 12, 18, 20, 14, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens, assistant_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb19ba6",
   "metadata": {},
   "source": [
    "## Running the fine tuning model job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31cd1602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-aa18bebf22194443bcb81d48bc4434ca\n",
      "Validation file ID: file-bbc5e0d7274c40d183333e1839a6d43a\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\",\n",
    "    user_provided_filename=training_file_name,\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\",\n",
    "    user_provided_filename=validation_file_name,\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650c2d8",
   "metadata": {},
   "source": [
    "# Fine tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd8636",
   "metadata": {},
   "source": [
    "**babbage-002** and **davinci-002** are not trained to follow instructions. Querying these base models should only be done as a point of reference to a fine-tuned version to evaluate the progress of your training.\n",
    "\n",
    "**gpt-35-turbo-0613** - fine-tuning of this model is limited to a subset of regions, and is not available in every region the base model is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11fe8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmodel = \"gpt-35-turbo-0613\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba5231cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-98c5a54e805a42678eb3286f52d76e1b\n",
      "Status: pending\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"pending\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"training_file\": \"file-aa18bebf22194443bcb81d48bc4434ca\",\n",
      "  \"validation_file\": \"file-bbc5e0d7274c40d183333e1839a6d43a\",\n",
      "  \"id\": \"ftjob-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"created_at\": 1698047499,\n",
      "  \"updated_at\": 1698047499,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=ftmodel,\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9939d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_training_status():\n",
    "    \"\"\"\n",
    "    Check fine tuning process\n",
    "    \"\"\"\n",
    "    response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "    if response[\"status\"] == \"pending\":\n",
    "        print(f\"Fine tuning of {ftmodel} is PENDING - Please wait\")\n",
    "\n",
    "    elif response[\"status\"] == \"running\":\n",
    "        print(\"\\033[1;31;34m\")\n",
    "        print(f\"Fine tuning of {ftmodel} is RUNNING - Please wait\")\n",
    "\n",
    "    elif response[\"status\"] == \"succeeded\":\n",
    "        print(\"\\033[1;31;32m\")\n",
    "        print(f\"Fine tuning of {ftmodel} is DONE!\")\n",
    "\n",
    "    else:\n",
    "        print(response)\n",
    "\n",
    "    print(\"\\nJob ID:\", job_id)\n",
    "    print(\"Created:\", datetime.datetime.utcfromtimestamp(response[\"created_at\"]))\n",
    "    print(\"Updated:\", datetime.datetime.utcfromtimestamp(response[\"updated_at\"]))\n",
    "\n",
    "    print(\"\\033[0m\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c7ed489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning of gpt-35-turbo-0613 is PENDING - Please wait\n",
      "\n",
      "Job ID: ftjob-98c5a54e805a42678eb3286f52d76e1b\n",
      "Created: 2023-10-23 07:51:39\n",
      "Updated: 2023-10-23 07:51:39\n",
      "\u001b[0m\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"pending\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"training_file\": \"file-aa18bebf22194443bcb81d48bc4434ca\",\n",
      "  \"validation_file\": \"file-bbc5e0d7274c40d183333e1839a6d43a\",\n",
      "  \"id\": \"ftjob-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"created_at\": 1698047499,\n",
      "  \"updated_at\": 1698047499,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_training_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f76b0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34m\n",
      "Fine tuning of gpt-35-turbo-0613 is RUNNING - Please wait\n",
      "\n",
      "Job ID: ftjob-98c5a54e805a42678eb3286f52d76e1b\n",
      "Created: 2023-10-23 07:51:39\n",
      "Updated: 2023-10-23 07:52:26\n",
      "\u001b[0m\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"running\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"training_file\": \"file-aa18bebf22194443bcb81d48bc4434ca\",\n",
      "  \"validation_file\": \"file-bbc5e0d7274c40d183333e1839a6d43a\",\n",
      "  \"id\": \"ftjob-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"created_at\": 1698047499,\n",
      "  \"updated_at\": 1698047546,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_training_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90868c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;32m\n",
      "Fine tuning of gpt-35-turbo-0613 is DONE!\n",
      "\n",
      "Job ID: ftjob-98c5a54e805a42678eb3286f52d76e1b\n",
      "Created: 2023-10-23 07:51:39\n",
      "Updated: 2023-10-23 08:39:43\n",
      "\u001b[0m\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"succeeded\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"training_file\": \"file-aa18bebf22194443bcb81d48bc4434ca\",\n",
      "  \"validation_file\": \"file-bbc5e0d7274c40d183333e1839a6d43a\",\n",
      "  \"result_files\": [\n",
      "    \"file-baebd298379b4f858922cb205345f5a4\"\n",
      "  ],\n",
      "  \"finished_at\": 1698050383,\n",
      "  \"trained_tokens\": 1048,\n",
      "  \"id\": \"ftjob-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"created_at\": 1698047499,\n",
      "  \"updated_at\": 1698050383,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_training_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c053c7",
   "metadata": {},
   "source": [
    "> https://oai.azure.com/portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "244ea49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7ff2e3751da0> JSON: {\n",
       "  \"has_more\": false,\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 2\n",
       "      },\n",
       "      \"status\": \"succeeded\",\n",
       "      \"model\": \"gpt-35-turbo-0613\",\n",
       "      \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b\",\n",
       "      \"training_file\": \"file-aa18bebf22194443bcb81d48bc4434ca\",\n",
       "      \"validation_file\": \"file-bbc5e0d7274c40d183333e1839a6d43a\",\n",
       "      \"result_files\": [\n",
       "        \"file-baebd298379b4f858922cb205345f5a4\"\n",
       "      ],\n",
       "      \"finished_at\": 1698050383,\n",
       "      \"trained_tokens\": 1048,\n",
       "      \"id\": \"ftjob-98c5a54e805a42678eb3286f52d76e1b\",\n",
       "      \"created_at\": 1698047499,\n",
       "      \"updated_at\": 1698050383,\n",
       "      \"object\": \"fine_tuning.job\"\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f931d",
   "metadata": {},
   "source": [
    "<img src=\"capture1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afdc9a",
   "metadata": {},
   "source": [
    "## Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3fa0df",
   "metadata": {},
   "source": [
    "- token:\tThere are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the Azure portal. Then run az account get-access-token. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable\n",
    "- subscription:\tThe subscription ID for the associated Azure OpenAI resource\n",
    "- resource_group:\tThe resource group name for your Azure OpenAI resource\n",
    "- resource_name:\tThe Azure OpenAI resource name\n",
    "- model_deployment_name:\tThe custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "635694c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"succeeded\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"training_file\": \"file-aa18bebf22194443bcb81d48bc4434ca\",\n",
      "  \"validation_file\": \"file-bbc5e0d7274c40d183333e1839a6d43a\",\n",
      "  \"result_files\": [\n",
      "    \"file-baebd298379b4f858922cb205345f5a4\"\n",
      "  ],\n",
      "  \"finished_at\": 1698050383,\n",
      "  \"trained_tokens\": 1048,\n",
      "  \"id\": \"ftjob-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"created_at\": 1698047499,\n",
      "  \"updated_at\": 1698050383,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "print(response)\n",
    "fine_tuned_model = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57b46218",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"TOKEN\")\n",
    "subscription = os.getenv(\"SUBSCRIPTION\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "resource_name = os.getenv(\"RESOURCE_NAME\")\n",
    "\n",
    "model_deployment_name = \"mymodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc77b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_params = {\"api-version\": \"2023-05-01\"}\n",
    "deploy_headers = {\n",
    "    \"Authorization\": \"Bearer {}\".format(token),\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b\",  # retrieve this value from the previous call\n",
    "            \"version\": \"1\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3f00c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sku\": {\"name\": \"standard\", \"capacity\": 1}, \"properties\": {\"model\": {\"format\": \"OpenAI\", \"name\": \"gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b\", \"version\": \"1\"}}}'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e21936f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a new deployment...\")\n",
    "resp = requests.put(\n",
    "    request_url, params=deploy_params, headers=deploy_headers, data=deploy_data\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "17baedf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created\n"
     ]
    }
   ],
   "source": [
    "print(resp.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3b382612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mymodel'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel = resp.json()[\"name\"]\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "828f5d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-10-23T09:10:34.1557354Z'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()[\"systemData\"][\"createdAt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "042216db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'OpenAI', 'name': 'gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b', 'version': '1'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()[\"properties\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4c0c5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment status of model 'mymodel': Creating\n"
     ]
    }
   ],
   "source": [
    "status = resp.json()[\"properties\"][\"provisioningState\"]\n",
    "\n",
    "print(f\"Model deployment status of model '{mymodel}': {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b40285f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment status of model 'mymodel': Succeeded\n"
     ]
    }
   ],
   "source": [
    "resp = requests.put(\n",
    "    request_url, params=deploy_params, headers=deploy_headers, data=deploy_data\n",
    ")\n",
    "\n",
    "status = resp.json()[\"properties\"][\"provisioningState\"]\n",
    "print(f\"Model deployment status of model '{mymodel}': {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9941add",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bf67a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_version = \"2023-05-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7cdd9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=mymodel, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "073cef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8ClnlcIlMElGYVmqD2phNQG9lxWdU\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698054377,\n",
      "  \"model\": \"gpt-35-turbo-0613.ft-98c5a54e805a42678eb3286f52d76e1b\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Yes, other Azure AI services also support customer managed keys. This allows customers to have more control over the encryption and security of their data.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 55,\n",
      "    \"completion_tokens\": 28,\n",
      "    \"total_tokens\": 83\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "55a477a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer type:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer type:\\n\\n\", type(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "77c27e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, other Azure AI services also support customer managed keys. This allows customers to have more control over the encryption and security of their data.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d94e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
